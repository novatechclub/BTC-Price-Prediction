{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef921758",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis for Sentiment Dataset\n",
    "This notebook provides a structured and thorough EDA across three platforms: **Twitter**, **Reddit**, and **Bitcointalk**. We explore the raw and engineered features through statistical and visual analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fb8d497",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import math\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3179d4b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>twitter_fomo</th>\n",
       "      <th>twitter_uncertain</th>\n",
       "      <th>twitter_hopeful</th>\n",
       "      <th>twitter_bearish</th>\n",
       "      <th>twitter_pessimistic_doubtful</th>\n",
       "      <th>twitter_sad</th>\n",
       "      <th>twitter_fearful_concerned</th>\n",
       "      <th>twitter_angry</th>\n",
       "      <th>twitter_mistrustful</th>\n",
       "      <th>...</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close_binance</th>\n",
       "      <th>volume</th>\n",
       "      <th>quote_asset_volume</th>\n",
       "      <th>num_trades</th>\n",
       "      <th>taker_buy_base_volume</th>\n",
       "      <th>taker_buy_quote_volume</th>\n",
       "      <th>close_augmento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-08-31 23:00:00</td>\n",
       "      <td>-0.44576</td>\n",
       "      <td>-0.942589</td>\n",
       "      <td>0.019913</td>\n",
       "      <td>-0.256830</td>\n",
       "      <td>-0.453646</td>\n",
       "      <td>-0.219225</td>\n",
       "      <td>0.197802</td>\n",
       "      <td>-0.395022</td>\n",
       "      <td>-0.183469</td>\n",
       "      <td>...</td>\n",
       "      <td>4699.00</td>\n",
       "      <td>4724.89</td>\n",
       "      <td>4683.36</td>\n",
       "      <td>4724.89</td>\n",
       "      <td>12.001618</td>\n",
       "      <td>56396.880782</td>\n",
       "      <td>162.0</td>\n",
       "      <td>9.227133</td>\n",
       "      <td>43376.763033</td>\n",
       "      <td>4734.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-09-01 00:00:00</td>\n",
       "      <td>-0.44576</td>\n",
       "      <td>0.196526</td>\n",
       "      <td>0.204217</td>\n",
       "      <td>-0.526668</td>\n",
       "      <td>-0.453646</td>\n",
       "      <td>-0.219225</td>\n",
       "      <td>1.312522</td>\n",
       "      <td>2.287562</td>\n",
       "      <td>-0.183469</td>\n",
       "      <td>...</td>\n",
       "      <td>4689.89</td>\n",
       "      <td>4745.35</td>\n",
       "      <td>4689.89</td>\n",
       "      <td>4721.05</td>\n",
       "      <td>15.711673</td>\n",
       "      <td>74145.736108</td>\n",
       "      <td>105.0</td>\n",
       "      <td>2.494201</td>\n",
       "      <td>11801.623970</td>\n",
       "      <td>4763.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-09-01 01:00:00</td>\n",
       "      <td>-0.44576</td>\n",
       "      <td>0.174289</td>\n",
       "      <td>-0.007331</td>\n",
       "      <td>0.075580</td>\n",
       "      <td>0.341731</td>\n",
       "      <td>-0.219225</td>\n",
       "      <td>0.167287</td>\n",
       "      <td>-0.395022</td>\n",
       "      <td>-0.183469</td>\n",
       "      <td>...</td>\n",
       "      <td>4730.05</td>\n",
       "      <td>4766.99</td>\n",
       "      <td>4701.11</td>\n",
       "      <td>4725.00</td>\n",
       "      <td>28.111344</td>\n",
       "      <td>133018.250682</td>\n",
       "      <td>270.0</td>\n",
       "      <td>9.947925</td>\n",
       "      <td>47251.438702</td>\n",
       "      <td>4771.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-09-01 02:00:00</td>\n",
       "      <td>-0.44576</td>\n",
       "      <td>0.196526</td>\n",
       "      <td>1.015152</td>\n",
       "      <td>-1.021372</td>\n",
       "      <td>0.622453</td>\n",
       "      <td>-0.219225</td>\n",
       "      <td>-0.504058</td>\n",
       "      <td>0.946270</td>\n",
       "      <td>-0.183469</td>\n",
       "      <td>...</td>\n",
       "      <td>4740.99</td>\n",
       "      <td>4767.00</td>\n",
       "      <td>4723.00</td>\n",
       "      <td>4735.96</td>\n",
       "      <td>15.140693</td>\n",
       "      <td>71825.621786</td>\n",
       "      <td>147.0</td>\n",
       "      <td>9.184023</td>\n",
       "      <td>43593.354559</td>\n",
       "      <td>4764.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-09-01 03:00:00</td>\n",
       "      <td>-0.44576</td>\n",
       "      <td>-0.468345</td>\n",
       "      <td>0.771871</td>\n",
       "      <td>-1.021372</td>\n",
       "      <td>-0.453646</td>\n",
       "      <td>-0.219225</td>\n",
       "      <td>-0.504058</td>\n",
       "      <td>-0.395022</td>\n",
       "      <td>-0.183469</td>\n",
       "      <td>...</td>\n",
       "      <td>4767.00</td>\n",
       "      <td>4767.00</td>\n",
       "      <td>4713.67</td>\n",
       "      <td>4714.73</td>\n",
       "      <td>16.684268</td>\n",
       "      <td>78802.109354</td>\n",
       "      <td>101.0</td>\n",
       "      <td>1.914899</td>\n",
       "      <td>9118.754582</td>\n",
       "      <td>4745.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date  twitter_fomo  twitter_uncertain  twitter_hopeful  \\\n",
       "0  2017-08-31 23:00:00      -0.44576          -0.942589         0.019913   \n",
       "1  2017-09-01 00:00:00      -0.44576           0.196526         0.204217   \n",
       "2  2017-09-01 01:00:00      -0.44576           0.174289        -0.007331   \n",
       "3  2017-09-01 02:00:00      -0.44576           0.196526         1.015152   \n",
       "4  2017-09-01 03:00:00      -0.44576          -0.468345         0.771871   \n",
       "\n",
       "   twitter_bearish  twitter_pessimistic_doubtful  twitter_sad  \\\n",
       "0        -0.256830                     -0.453646    -0.219225   \n",
       "1        -0.526668                     -0.453646    -0.219225   \n",
       "2         0.075580                      0.341731    -0.219225   \n",
       "3        -1.021372                      0.622453    -0.219225   \n",
       "4        -1.021372                     -0.453646    -0.219225   \n",
       "\n",
       "   twitter_fearful_concerned  twitter_angry  twitter_mistrustful  ...  \\\n",
       "0                   0.197802      -0.395022            -0.183469  ...   \n",
       "1                   1.312522       2.287562            -0.183469  ...   \n",
       "2                   0.167287      -0.395022            -0.183469  ...   \n",
       "3                  -0.504058       0.946270            -0.183469  ...   \n",
       "4                  -0.504058      -0.395022            -0.183469  ...   \n",
       "\n",
       "      open     high      low  close_binance     volume  quote_asset_volume  \\\n",
       "0  4699.00  4724.89  4683.36        4724.89  12.001618        56396.880782   \n",
       "1  4689.89  4745.35  4689.89        4721.05  15.711673        74145.736108   \n",
       "2  4730.05  4766.99  4701.11        4725.00  28.111344       133018.250682   \n",
       "3  4740.99  4767.00  4723.00        4735.96  15.140693        71825.621786   \n",
       "4  4767.00  4767.00  4713.67        4714.73  16.684268        78802.109354   \n",
       "\n",
       "   num_trades  taker_buy_base_volume  taker_buy_quote_volume  close_augmento  \n",
       "0       162.0               9.227133            43376.763033         4734.26  \n",
       "1       105.0               2.494201            11801.623970         4763.99  \n",
       "2       270.0               9.947925            47251.438702         4771.30  \n",
       "3       147.0               9.184023            43593.354559         4764.00  \n",
       "4       101.0               1.914899             9118.754582         4745.60  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"Data/baseline_data_v1.csv\")\n",
    "\n",
    "# Show a preview\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9999470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# UTILITY SECTION\n",
    "# =========================\n",
    "\n",
    "import logging\n",
    "import pandas as pd\n",
    "import sys\n",
    "import re\n",
    "\n",
    "# ---- ANSI Color Codes ----\n",
    "class ColorCodes:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKCYAN = '\\033[96m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    RED = '\\033[31m'\n",
    "    GREEN = '\\033[32m'\n",
    "    YELLOW = '\\033[33m'\n",
    "    BLUE = '\\033[34m'\n",
    "    MAGENTA = '\\033[35m'\n",
    "    CYAN = '\\033[36m'\n",
    "    WHITE = '\\033[37m'\n",
    "    BLACK = '\\033[30m'\n",
    "\n",
    "# ---- Strip ANSI for File Logs ----\n",
    "class StripColorFormatter(logging.Formatter):\n",
    "    ansi_escape = re.compile(r'(?:\\x1B[@-_][0-?]*[ -/]*[@-~])')\n",
    "    def format(self, record):\n",
    "        message = super().format(record)\n",
    "        return self.ansi_escape.sub('', message)\n",
    "\n",
    "# ---- Logger Initialization ----\n",
    "def reinitialize_logger(name=\"DualLogger\", log_file=\"eda_output.log\", level=logging.INFO):\n",
    "    logger = logging.getLogger(name)\n",
    "    logger.setLevel(level)\n",
    "\n",
    "    if logger.hasHandlers():\n",
    "        logger.handlers.clear()\n",
    "\n",
    "    console_handler = logging.StreamHandler(sys.stdout)\n",
    "    console_handler.setLevel(level)\n",
    "    console_handler.setFormatter(logging.Formatter('%(message)s'))\n",
    "\n",
    "    file_handler = logging.FileHandler(log_file, mode='w')\n",
    "    file_handler.setLevel(level)\n",
    "    file_handler.setFormatter(StripColorFormatter('%(message)s'))\n",
    "\n",
    "    logger.addHandler(console_handler)\n",
    "    logger.addHandler(file_handler)\n",
    "\n",
    "    return logger\n",
    "\n",
    "# ---- Initialize Logger ----\n",
    "log = reinitialize_logger()\n",
    "\n",
    "\n",
    "# =========================\n",
    "# DATA WRANGLER SECTION\n",
    "# =========================\n",
    "\n",
    "class DataWrangler:\n",
    "    def __init__(self, path):\n",
    "        self.df = self._load_data(path)\n",
    "        self.cleaned = None\n",
    "        self.transformed = None\n",
    "\n",
    "    def _load_data(self, path):\n",
    "        df = pd.read_csv(path)\n",
    "        self.df = df\n",
    "        self._get_columns()\n",
    "        df.dropna(axis=0, how='any', inplace=True)\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        return df\n",
    "\n",
    "    def _get_columns(self):\n",
    "        log.info(\"üîç Columns in the dataset:\")\n",
    "        for col in self.df.columns:\n",
    "            log.info(f\"  ‚Ä¢ {col}\")\n",
    "\n",
    "    def clean_data(self):\n",
    "        df = self.df.copy()\n",
    "        df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "        df.dropna(axis=0, how='any', inplace=True)\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        self.cleaned = df\n",
    "        return df\n",
    "\n",
    "    def engineer_relative_features(self, platform_keywords):\n",
    "        df = self.cleaned.copy()\n",
    "        for platform in platform_keywords:\n",
    "            cols = [col for col in df.columns if col.startswith(platform + \"_\") and not col.endswith(\"total\")]\n",
    "            df[platform + '_total'] = df[cols].sum(axis=1)\n",
    "            for col in cols:\n",
    "                new_col = col + \"_relative\"\n",
    "                df[new_col] = df[col] / df[platform + '_total']\n",
    "        self.transformed = df\n",
    "        return df\n",
    "\n",
    "    def get_platform_data(self, platform):\n",
    "        if self.cleaned is None:\n",
    "            raise ValueError(\"Data must be cleaned first.\")\n",
    "        return self.cleaned[[col for col in self.cleaned.columns if col.startswith(platform)] + ['date']]\n",
    "\n",
    "    def summarize_basic_dataset(self, df: pd.DataFrame = None, num_examples: int = 5):\n",
    "        \"\"\"\n",
    "        Display a color-coded summary of the dataset using the shared logger\n",
    "        \"\"\"\n",
    "        if df is None:\n",
    "            df = self.df\n",
    "        c = ColorCodes\n",
    "\n",
    "        log.info(f\"\\n\\n\\n{c.BOLD}{c.HEADER}Preview of the data with all columns{c.ENDC}\")\n",
    "        log.info(f\"{c.OKBLUE}--------------------------------------------------------{c.ENDC}\")\n",
    "        with pd.option_context('display.max_columns', None):\n",
    "            log.info(f\"\\n{df.head()}\")\n",
    "\n",
    "        log.info(f\"\\n\\n\\n{c.BOLD}{c.HEADER}Overview of columns{c.ENDC}\")\n",
    "        log.info(f\"{c.OKBLUE}--------------------------------------------------------{c.ENDC}\")\n",
    "        log.info(f\"{df.columns.tolist()}\")\n",
    "        log.info(f\"Shape: {df.shape}\")\n",
    "\n",
    "        log.info(f\"\\n\\n\\n{c.BOLD}{c.HEADER}Detailed overview of columns, data types, null values, and unique values{c.ENDC}\")\n",
    "        log.info(f\"{c.OKBLUE}--------------------------------------------------------{c.ENDC}\")\n",
    "        log.info(f\"{c.UNDERLINE}Column name | Data type | Null values | Num Unique values{c.ENDC}\")\n",
    "        log.info(f\"{c.OKBLUE}--------------------------------------------------------{c.ENDC}\")\n",
    "\n",
    "        for col in df.columns:\n",
    "            nulls = df[col].isnull().sum()\n",
    "            unique_vals = df[col].unique()\n",
    "            num_unique = len(unique_vals)\n",
    "            dtype = df[col].dtype\n",
    "        \n",
    "            log.info(f\"{c.CYAN}{col:<30}{c.ENDC} {c.GREEN}{str(dtype):<10}{c.ENDC} \"\n",
    "                     f\"{c.YELLOW}{nulls:<10}{c.ENDC} {c.MAGENTA}{num_unique}{c.ENDC}\")\n",
    "        \n",
    "            # Print basic stats if it's numeric\n",
    "            if pd.api.types.is_numeric_dtype(df[col]):\n",
    "                min_val = df[col].min()\n",
    "                max_val = df[col].max()\n",
    "                mean_val = df[col].mean()\n",
    "                median_val = df[col].median()\n",
    "                log.info(f\"   ‚Ü≥ {c.OKBLUE}Min:{c.ENDC} {min_val} | {c.OKBLUE}Max:{c.ENDC} {max_val} | \"\n",
    "                         f\"{c.OKBLUE}Mean:{c.ENDC} {mean_val} | {c.OKBLUE}Median:{c.ENDC} {median_val}\")\n",
    "        \n",
    "            # Show unique values (up to 15), regardless of dtype\n",
    "            if num_unique <= num_examples or pd.api.types.is_numeric_dtype(df[col]):\n",
    "                sample_uniques = unique_vals[:num_examples]\n",
    "                formatted_uniques = \", \".join(map(str, sample_uniques))\n",
    "                log.info(f\"   ‚Ü≥ {c.OKCYAN}Sample unique values:{c.ENDC} {formatted_uniques}\")\n",
    "\n",
    "    def convert_string_dates(self, df: pd.DataFrame = None, max_error_rate: float = 0.2):\n",
    "        \"\"\"\n",
    "        Automatically detect and convert string-based date columns into datetime columns.\n",
    "        Adds new columns with '_datetime' suffix. Original columns remain unchanged.\n",
    "        Skips columns where conversion fails or too many entries become NaT.\n",
    "        \"\"\"\n",
    "        if df is None:\n",
    "            df = self.df\n",
    "\n",
    "        c = ColorCodes\n",
    "        log.info(f\"\\n\\n{c.BOLD}{c.HEADER}üîÑ Attempting to convert string-based date columns...{c.ENDC}\")\n",
    "\n",
    "        for col in df.columns:\n",
    "            if df[col].dtype == 'object':\n",
    "                try:\n",
    "                    converted = pd.to_datetime(df[col], errors='coerce', infer_datetime_format=True)\n",
    "                    num_parsed = converted.notna().sum()\n",
    "                    total = len(df)\n",
    "                    error_ratio = 1 - (num_parsed / total)\n",
    "\n",
    "                    if 0 < error_ratio <= max_error_rate:\n",
    "                        new_col = col + \"_datetime\"\n",
    "                        df[new_col] = converted\n",
    "                        log.info(f\"{c.GREEN}‚úî Partially converted:{c.ENDC} '{col}' ‚Üí '{new_col}' \"\n",
    "                                 f\"({num_parsed}/{total} parsed, {round((1-error_ratio)*100, 1)}% success)\")\n",
    "                    elif error_ratio == 0:\n",
    "                        new_col = col + \"_datetime\"\n",
    "                        df[new_col] = converted\n",
    "                        log.info(f\"{c.OKGREEN}‚úî Fully converted:{c.ENDC} '{col}' ‚Üí '{new_col}' (100% success)\")\n",
    "                    else:\n",
    "                        log.warning(f\"{c.WARNING}‚ö† Skipped column '{col}' due to high parsing failure \"\n",
    "                                    f\"({round(error_ratio * 100, 1)}% unparsed){c.ENDC}\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    log.error(f\"{c.FAIL}‚úñ Error while parsing column '{col}': {str(e)}{c.ENDC}\")\n",
    "\n",
    "        self.df = df\n",
    "        return df\n",
    "\n",
    "    def extract_datetime_features(self, df: pd.DataFrame = None, features: list = None, columns: list = None):\n",
    "        \"\"\"\n",
    "        Extracts specified datetime features from datetime columns in the DataFrame (non-destructive).\n",
    "        Result is saved in self.transformed, preserving the original data.\n",
    "\n",
    "        :param df: DataFrame to work on. Defaults to self.df.\n",
    "        :param features: List of datetime features to extract. Defaults to all.\n",
    "        :param columns: Optional list of specific datetime columns to extract from.\n",
    "        \"\"\"\n",
    "        if df is None:\n",
    "            df = self.df\n",
    "\n",
    "        df = df.copy()  # non-destructive\n",
    "        c = ColorCodes\n",
    "\n",
    "        if features is None:\n",
    "            features = ['year', 'month', 'month_name', 'day', 'weekday', 'day_name', 'hour', 'minute', 'is_weekend']\n",
    "\n",
    "        log.info(f\"\\n\\n{c.BOLD}{c.HEADER}üß† Extracting datetime features (non-destructive)...{c.ENDC}\")\n",
    "\n",
    "        # Filter datetime columns\n",
    "        datetime_cols = df.select_dtypes(include=['datetime64[ns]']).columns.tolist()\n",
    "        if columns:\n",
    "            datetime_cols = [col for col in columns if col in datetime_cols]\n",
    "\n",
    "        if not datetime_cols:\n",
    "            log.warning(f\"{c.WARNING}‚ö† No valid datetime columns found to extract from.{c.ENDC}\")\n",
    "            return df\n",
    "\n",
    "        for col in datetime_cols:\n",
    "            for feature in features:\n",
    "                try:\n",
    "                    new_col = f\"{col}_{feature}\"\n",
    "                    if feature == 'year':\n",
    "                        df[new_col] = df[col].dt.year\n",
    "                    elif feature == 'month':\n",
    "                        df[new_col] = df[col].dt.month\n",
    "                    elif feature == 'month_name':\n",
    "                        df[new_col] = df[col].dt.month_name()\n",
    "                    elif feature == 'day':\n",
    "                        df[new_col] = df[col].dt.day\n",
    "                    elif feature == 'weekday':\n",
    "                        df[new_col] = df[col].dt.weekday\n",
    "                    elif feature == 'day_name':\n",
    "                        df[new_col] = df[col].dt.day_name()\n",
    "                    elif feature == 'hour':\n",
    "                        df[new_col] = df[col].dt.hour\n",
    "                    elif feature == 'minute':\n",
    "                        df[new_col] = df[col].dt.minute\n",
    "                    elif feature == 'is_weekend':\n",
    "                        df[new_col] = df[col].dt.weekday >= 5\n",
    "                    else:\n",
    "                        log.warning(f\"{c.WARNING}‚ö† Unsupported feature: '{feature}' skipped.{c.ENDC}\")\n",
    "                        continue\n",
    "\n",
    "                    log.info(f\"{c.OKGREEN}‚úî Extracted:{c.ENDC} {new_col} from {col}\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    log.error(f\"{c.FAIL}‚úñ Failed to extract {feature} from {col}: {str(e)}{c.ENDC}\")\n",
    "\n",
    "        self.transformed = df\n",
    "        return df\n",
    "\n",
    "\n",
    "    def clean_currency_fields(self, df: pd.DataFrame = None, inplace: bool = False, convert_to_float: bool = True):\n",
    "        \"\"\"\n",
    "        Cleans and standardizes currency-formatted strings in the DataFrame.\n",
    "        - Handles mixed decimal separators (e.g., 1.000,00‚Ç¨ vs $1,000.00)\n",
    "        - Removes symbols, commas, etc.\n",
    "        - Optionally converts to float\n",
    "        - Adds a column with inferred currency type (e.g., USD, EUR)\n",
    "        \"\"\"\n",
    "        if df is None:\n",
    "            df = self.df\n",
    "\n",
    "        if not inplace:\n",
    "            df = df.copy()\n",
    "\n",
    "        import numpy as np\n",
    "\n",
    "        c = ColorCodes\n",
    "        currency_map = {\n",
    "            \"$\": \"USD\",\n",
    "            \"‚Ç¨\": \"EUR\",\n",
    "            \"¬£\": \"GBP\",\n",
    "            \"¬•\": \"JPY\",\n",
    "            \"‚ÇΩ\": \"RUB\",\n",
    "            \"‚Çπ\": \"INR\"\n",
    "        }\n",
    "\n",
    "        currency_symbols = list(currency_map.keys())\n",
    "        log.info(f\"\\n\\n{c.BOLD}{c.HEADER}üí∞ Cleaning currency fields with intelligent separator handling...{c.ENDC}\")\n",
    "\n",
    "        for col in df.columns:\n",
    "            if df[col].dtype == \"object\":\n",
    "                try:\n",
    "                    sample = df[col].dropna().astype(str).head(50)\n",
    "\n",
    "                    if any(sym in val for val in sample for sym in currency_symbols) or sample.str.contains(r\"\\d{1,3}[\\.,]\\d{2,3}\").any():\n",
    "                        cleaned_col = df[col].astype(str)\n",
    "\n",
    "                        # Extract currency type from first matching symbol\n",
    "                        def detect_currency_symbol(val):\n",
    "                            for sym in currency_symbols:\n",
    "                                if sym in val:\n",
    "                                    return currency_map[sym]\n",
    "                            return \"UNKNOWN\"\n",
    "\n",
    "                        df[col + \"_currency_type\"] = df[col].apply(detect_currency_symbol)\n",
    "\n",
    "                        # Remove currency symbols and normalize\n",
    "                        cleaned_col = cleaned_col.str.replace(r\"[^\\d,.\\-]\", \"\", regex=True)\n",
    "\n",
    "                        # Detect format style\n",
    "                        dot_comma = sample.str.contains(r\"\\.\\d{3},\\d{2}\", regex=True).any()\n",
    "                        comma_dot = sample.str.contains(r\",\\d{3}\\.\\d{2}\", regex=True).any()\n",
    "\n",
    "                        if dot_comma:\n",
    "                            cleaned_col = cleaned_col.str.replace(\".\", \"\", regex=False)\n",
    "                            cleaned_col = cleaned_col.str.replace(\",\", \".\", regex=False)\n",
    "                            style = \"dot-comma (EU)\"\n",
    "                        elif comma_dot:\n",
    "                            cleaned_col = cleaned_col.str.replace(\",\", \"\", regex=False)\n",
    "                            style = \"comma-dot (US)\"\n",
    "                        else:\n",
    "                            # Fallback auto-detection\n",
    "                            def standardize(val):\n",
    "                                if val.count(\",\") > 0 and val.rfind(\",\") > val.rfind(\".\"):\n",
    "                                    val = val.replace(\".\", \"\").replace(\",\", \".\")\n",
    "                                else:\n",
    "                                    val = val.replace(\",\", \"\")\n",
    "                                return val\n",
    "                            cleaned_col = cleaned_col.apply(standardize)\n",
    "                            style = \"auto-detected\"\n",
    "\n",
    "                        # Convert to float\n",
    "                        if convert_to_float:\n",
    "                            df[col + \"_cleaned\"] = pd.to_numeric(cleaned_col, errors='coerce')\n",
    "                            converted = df[col + \"_cleaned\"].notna().sum()\n",
    "                            total = len(df)\n",
    "                            log.info(f\"{c.OKGREEN}‚úî Cleaned '{col}' ({converted}/{total} parsed, {style}){c.ENDC}\")\n",
    "                            log.info(f\"   ‚Ü≥ {c.CYAN}Currency type column:{c.ENDC} '{col}_currency_type'\")\n",
    "                        else:\n",
    "                            df[col + \"_cleaned\"] = cleaned_col\n",
    "                            log.info(f\"{c.OKCYAN}‚û§ Cleaned '{col}' as standardized strings ({style}){c.ENDC}\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    log.error(f\"{c.FAIL}‚úñ Error cleaning column '{col}': {str(e)}{c.ENDC}\")\n",
    "\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "06b6064d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Columns in the dataset:\n",
      "  ‚Ä¢ date\n",
      "  ‚Ä¢ twitter_fomo\n",
      "  ‚Ä¢ twitter_uncertain\n",
      "  ‚Ä¢ twitter_hopeful\n",
      "  ‚Ä¢ twitter_bearish\n",
      "  ‚Ä¢ twitter_pessimistic_doubtful\n",
      "  ‚Ä¢ twitter_sad\n",
      "  ‚Ä¢ twitter_fearful_concerned\n",
      "  ‚Ä¢ twitter_angry\n",
      "  ‚Ä¢ twitter_mistrustful\n",
      "  ‚Ä¢ twitter_panicking\n",
      "  ‚Ä¢ twitter_annoyed_frustrated\n",
      "  ‚Ä¢ twitter_bullish\n",
      "  ‚Ä¢ twitter_optimistic\n",
      "  ‚Ä¢ twitter_happy\n",
      "  ‚Ä¢ twitter_euphoric_excited\n",
      "  ‚Ä¢ reddit_fomo\n",
      "  ‚Ä¢ reddit_uncertain\n",
      "  ‚Ä¢ reddit_hopeful\n",
      "  ‚Ä¢ reddit_bearish\n",
      "  ‚Ä¢ reddit_pessimistic_doubtful\n",
      "  ‚Ä¢ reddit_sad\n",
      "  ‚Ä¢ reddit_fearful_concerned\n",
      "  ‚Ä¢ reddit_angry\n",
      "  ‚Ä¢ reddit_mistrustful\n",
      "  ‚Ä¢ reddit_panicking\n",
      "  ‚Ä¢ reddit_annoyed_frustrated\n",
      "  ‚Ä¢ reddit_bullish\n",
      "  ‚Ä¢ reddit_optimistic\n",
      "  ‚Ä¢ reddit_happy\n",
      "  ‚Ä¢ reddit_euphoric_excited\n",
      "  ‚Ä¢ bitcointalk_fomo\n",
      "  ‚Ä¢ bitcointalk_uncertain\n",
      "  ‚Ä¢ bitcointalk_hopeful\n",
      "  ‚Ä¢ bitcointalk_bearish\n",
      "  ‚Ä¢ bitcointalk_pessimistic_doubtful\n",
      "  ‚Ä¢ bitcointalk_sad\n",
      "  ‚Ä¢ bitcointalk_fearful_concerned\n",
      "  ‚Ä¢ bitcointalk_angry\n",
      "  ‚Ä¢ bitcointalk_mistrustful\n",
      "  ‚Ä¢ bitcointalk_panicking\n",
      "  ‚Ä¢ bitcointalk_annoyed_frustrated\n",
      "  ‚Ä¢ bitcointalk_bullish\n",
      "  ‚Ä¢ bitcointalk_optimistic\n",
      "  ‚Ä¢ bitcointalk_happy\n",
      "  ‚Ä¢ bitcointalk_euphoric_excited\n",
      "  ‚Ä¢ open\n",
      "  ‚Ä¢ high\n",
      "  ‚Ä¢ low\n",
      "  ‚Ä¢ close_binance\n",
      "  ‚Ä¢ volume\n",
      "  ‚Ä¢ quote_asset_volume\n",
      "  ‚Ä¢ num_trades\n",
      "  ‚Ä¢ taker_buy_base_volume\n",
      "  ‚Ä¢ taker_buy_quote_volume\n",
      "  ‚Ä¢ close_augmento\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95müîÑ Attempting to convert string-based date columns...\u001b[0m\n",
      "\u001b[92m‚úî Fully converted:\u001b[0m 'date' ‚Üí 'date_datetime' (100% success)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/46/2hncg7dx7pj7wxcm2xg6vc280000gn/T/ipykernel_45257/261830483.py:171: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  converted = pd.to_datetime(df[col], errors='coerce', infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m\u001b[95müß† Extracting datetime features (non-destructive)...\u001b[0m\n",
      "\u001b[92m‚úî Extracted:\u001b[0m date_datetime_year from date_datetime\n",
      "\u001b[92m‚úî Extracted:\u001b[0m date_datetime_month from date_datetime\n",
      "\u001b[92m‚úî Extracted:\u001b[0m date_datetime_month_name from date_datetime\n",
      "\u001b[92m‚úî Extracted:\u001b[0m date_datetime_day from date_datetime\n",
      "\u001b[92m‚úî Extracted:\u001b[0m date_datetime_weekday from date_datetime\n",
      "\u001b[92m‚úî Extracted:\u001b[0m date_datetime_day_name from date_datetime\n",
      "\u001b[92m‚úî Extracted:\u001b[0m date_datetime_hour from date_datetime\n",
      "\u001b[92m‚úî Extracted:\u001b[0m date_datetime_minute from date_datetime\n",
      "\u001b[92m‚úî Extracted:\u001b[0m date_datetime_is_weekend from date_datetime\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95mPreview of the data with all columns\u001b[0m\n",
      "\u001b[94m--------------------------------------------------------\u001b[0m\n",
      "\n",
      "                  date  twitter_fomo  twitter_uncertain  twitter_hopeful  \\\n",
      "0  2017-08-31 23:00:00      -0.44576          -0.942589         0.019913   \n",
      "1  2017-09-01 00:00:00      -0.44576           0.196526         0.204217   \n",
      "2  2017-09-01 01:00:00      -0.44576           0.174289        -0.007331   \n",
      "3  2017-09-01 02:00:00      -0.44576           0.196526         1.015152   \n",
      "4  2017-09-01 03:00:00      -0.44576          -0.468345         0.771871   \n",
      "\n",
      "   twitter_bearish  twitter_pessimistic_doubtful  twitter_sad  \\\n",
      "0        -0.256830                     -0.453646    -0.219225   \n",
      "1        -0.526668                     -0.453646    -0.219225   \n",
      "2         0.075580                      0.341731    -0.219225   \n",
      "3        -1.021372                      0.622453    -0.219225   \n",
      "4        -1.021372                     -0.453646    -0.219225   \n",
      "\n",
      "   twitter_fearful_concerned  twitter_angry  twitter_mistrustful  \\\n",
      "0                   0.197802      -0.395022            -0.183469   \n",
      "1                   1.312522       2.287562            -0.183469   \n",
      "2                   0.167287      -0.395022            -0.183469   \n",
      "3                  -0.504058       0.946270            -0.183469   \n",
      "4                  -0.504058      -0.395022            -0.183469   \n",
      "\n",
      "   twitter_panicking  twitter_annoyed_frustrated  twitter_bullish  \\\n",
      "0          -0.180872                   -0.160681         1.448106   \n",
      "1          -0.180872                    3.379975        -1.042846   \n",
      "2          -0.180872                    2.456325         0.739976   \n",
      "3          -0.180872                   -0.160681        -1.042846   \n",
      "4          -0.180872                   -0.160681         0.145147   \n",
      "\n",
      "   twitter_optimistic  twitter_happy  twitter_euphoric_excited  reddit_fomo  \\\n",
      "0           -0.015329      -0.468776                  0.236334     0.596945   \n",
      "1           -0.618845       0.488265                  0.594047     0.145456   \n",
      "2           -0.399878      -0.468776                 -0.592107    -0.141003   \n",
      "3            0.296834       0.488265                  1.118692    -0.199059   \n",
      "4           -0.298357      -0.468776                  2.587698    -0.279165   \n",
      "\n",
      "   reddit_uncertain  reddit_hopeful  reddit_bearish  \\\n",
      "0         -0.524057        0.953470       -0.333040   \n",
      "1         -0.056921       -0.782740       -0.109307   \n",
      "2          0.019843        0.335702        1.025185   \n",
      "3          0.422672        1.098536       -0.243298   \n",
      "4         -1.362543        0.411147       -0.026482   \n",
      "\n",
      "   reddit_pessimistic_doubtful  reddit_sad  reddit_fearful_concerned  \\\n",
      "0                    -0.343830    2.504352                 -0.810077   \n",
      "1                     0.946843    0.356498                  0.461368   \n",
      "2                     0.322114   -0.438621                 -0.434686   \n",
      "3                    -0.669677   -0.438621                  0.488282   \n",
      "4                     0.395159    0.432951                 -0.672144   \n",
      "\n",
      "   reddit_angry  reddit_mistrustful  reddit_panicking  \\\n",
      "0      0.143373            0.199307          0.669972   \n",
      "1     -0.414478           -0.460464         -0.236031   \n",
      "2      0.399138           -0.460464         -0.236031   \n",
      "3     -0.292621           -0.460464         -0.236031   \n",
      "4      2.634869           -0.460464         -0.236031   \n",
      "\n",
      "   reddit_annoyed_frustrated  reddit_bullish  reddit_optimistic  reddit_happy  \\\n",
      "0                  -0.309501       -0.349722           0.111294      0.959361   \n",
      "1                  -0.309501       -0.271962           0.242322      1.195157   \n",
      "2                  -0.309501        0.858245          -0.305072     -0.916041   \n",
      "3                   2.920969       -0.653777          -0.196933      0.153633   \n",
      "4                   1.088298       -0.742556           1.137197      0.009638   \n",
      "\n",
      "   reddit_euphoric_excited  bitcointalk_fomo  bitcointalk_uncertain  \\\n",
      "0                -0.050449          1.012681              -1.109870   \n",
      "1                -0.681684          0.295534              -0.403499   \n",
      "2                -0.289787         -0.504359              -0.288739   \n",
      "3                -0.159481         -0.504359              -0.083809   \n",
      "4                -0.144803         -0.131528               0.649768   \n",
      "\n",
      "   bitcointalk_hopeful  bitcointalk_bearish  bitcointalk_pessimistic_doubtful  \\\n",
      "0             0.947213            -0.063584                         -0.965435   \n",
      "1            -0.724517            -0.240571                          0.003950   \n",
      "2             0.290775             0.205744                         -0.157614   \n",
      "3             1.514564            -0.910043                          1.414752   \n",
      "4            -0.505111            -0.910043                         -0.287687   \n",
      "\n",
      "   bitcointalk_sad  bitcointalk_fearful_concerned  bitcointalk_angry  \\\n",
      "0        -0.283359                      -0.663846          -0.340122   \n",
      "1        -0.283359                      -0.341649          -0.340122   \n",
      "2        -0.283359                       0.410143          -0.340122   \n",
      "3         1.172342                      -0.663846          -0.340122   \n",
      "4        -0.283359                      -0.063140           0.865830   \n",
      "\n",
      "   bitcointalk_mistrustful  bitcointalk_panicking  \\\n",
      "0                -0.338894              -0.265090   \n",
      "1                -0.338894               0.707228   \n",
      "2                -0.338894               1.355441   \n",
      "3                -0.338894              -0.265090   \n",
      "4                 0.195239               0.641308   \n",
      "\n",
      "   bitcointalk_annoyed_frustrated  bitcointalk_bullish  \\\n",
      "0                       -0.153949            -0.453770   \n",
      "1                        1.145217             0.915158   \n",
      "2                       -0.153949             0.092055   \n",
      "3                       -0.153949            -0.428038   \n",
      "4                       -0.153949            -0.820120   \n",
      "\n",
      "   bitcointalk_optimistic  bitcointalk_happy  bitcointalk_euphoric_excited  \\\n",
      "0                1.091415           0.041980                      0.665312   \n",
      "1                0.014141           0.433008                      0.208604   \n",
      "2               -0.153821          -0.039484                      0.478901   \n",
      "3               -0.273794           0.065983                      0.189297   \n",
      "4                1.034725           0.030589                     -0.368638   \n",
      "\n",
      "      open     high      low  close_binance     volume  quote_asset_volume  \\\n",
      "0  4699.00  4724.89  4683.36        4724.89  12.001618        56396.880782   \n",
      "1  4689.89  4745.35  4689.89        4721.05  15.711673        74145.736108   \n",
      "2  4730.05  4766.99  4701.11        4725.00  28.111344       133018.250682   \n",
      "3  4740.99  4767.00  4723.00        4735.96  15.140693        71825.621786   \n",
      "4  4767.00  4767.00  4713.67        4714.73  16.684268        78802.109354   \n",
      "\n",
      "   num_trades  taker_buy_base_volume  taker_buy_quote_volume  close_augmento  \\\n",
      "0       162.0               9.227133            43376.763033         4734.26   \n",
      "1       105.0               2.494201            11801.623970         4763.99   \n",
      "2       270.0               9.947925            47251.438702         4771.30   \n",
      "3       147.0               9.184023            43593.354559         4764.00   \n",
      "4       101.0               1.914899             9118.754582         4745.60   \n",
      "\n",
      "        date_datetime  date_datetime_year  date_datetime_month  \\\n",
      "0 2017-08-31 23:00:00                2017                    8   \n",
      "1 2017-09-01 00:00:00                2017                    9   \n",
      "2 2017-09-01 01:00:00                2017                    9   \n",
      "3 2017-09-01 02:00:00                2017                    9   \n",
      "4 2017-09-01 03:00:00                2017                    9   \n",
      "\n",
      "  date_datetime_month_name  date_datetime_day  date_datetime_weekday  \\\n",
      "0                   August                 31                      3   \n",
      "1                September                  1                      4   \n",
      "2                September                  1                      4   \n",
      "3                September                  1                      4   \n",
      "4                September                  1                      4   \n",
      "\n",
      "  date_datetime_day_name  date_datetime_hour  date_datetime_minute  \\\n",
      "0               Thursday                  23                     0   \n",
      "1                 Friday                   0                     0   \n",
      "2                 Friday                   1                     0   \n",
      "3                 Friday                   2                     0   \n",
      "4                 Friday                   3                     0   \n",
      "\n",
      "   date_datetime_is_weekend  \n",
      "0                     False  \n",
      "1                     False  \n",
      "2                     False  \n",
      "3                     False  \n",
      "4                     False  \n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95mOverview of columns\u001b[0m\n",
      "\u001b[94m--------------------------------------------------------\u001b[0m\n",
      "['date', 'twitter_fomo', 'twitter_uncertain', 'twitter_hopeful', 'twitter_bearish', 'twitter_pessimistic_doubtful', 'twitter_sad', 'twitter_fearful_concerned', 'twitter_angry', 'twitter_mistrustful', 'twitter_panicking', 'twitter_annoyed_frustrated', 'twitter_bullish', 'twitter_optimistic', 'twitter_happy', 'twitter_euphoric_excited', 'reddit_fomo', 'reddit_uncertain', 'reddit_hopeful', 'reddit_bearish', 'reddit_pessimistic_doubtful', 'reddit_sad', 'reddit_fearful_concerned', 'reddit_angry', 'reddit_mistrustful', 'reddit_panicking', 'reddit_annoyed_frustrated', 'reddit_bullish', 'reddit_optimistic', 'reddit_happy', 'reddit_euphoric_excited', 'bitcointalk_fomo', 'bitcointalk_uncertain', 'bitcointalk_hopeful', 'bitcointalk_bearish', 'bitcointalk_pessimistic_doubtful', 'bitcointalk_sad', 'bitcointalk_fearful_concerned', 'bitcointalk_angry', 'bitcointalk_mistrustful', 'bitcointalk_panicking', 'bitcointalk_annoyed_frustrated', 'bitcointalk_bullish', 'bitcointalk_optimistic', 'bitcointalk_happy', 'bitcointalk_euphoric_excited', 'open', 'high', 'low', 'close_binance', 'volume', 'quote_asset_volume', 'num_trades', 'taker_buy_base_volume', 'taker_buy_quote_volume', 'close_augmento', 'date_datetime', 'date_datetime_year', 'date_datetime_month', 'date_datetime_month_name', 'date_datetime_day', 'date_datetime_weekday', 'date_datetime_day_name', 'date_datetime_hour', 'date_datetime_minute', 'date_datetime_is_weekend']\n",
      "Shape: (64235, 66)\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95mDetailed overview of columns, data types, null values, and unique values\u001b[0m\n",
      "\u001b[94m--------------------------------------------------------\u001b[0m\n",
      "\u001b[4mColumn name | Data type | Null values | Num Unique values\u001b[0m\n",
      "\u001b[94m--------------------------------------------------------\u001b[0m\n",
      "\u001b[36mdate                          \u001b[0m \u001b[32mobject    \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m64235\u001b[0m\n",
      "\u001b[36mtwitter_fomo                  \u001b[0m \u001b[32mfloat64   \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m448\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m -0.4457595547923649 | \u001b[94mMax:\u001b[0m 18.17238884347415 | \u001b[94mMean:\u001b[0m -0.008258238250390086 | \u001b[94mMedian:\u001b[0m -0.4457595547923649\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m -0.4457595547923649, 2.6572651782520538, 0.4408189403631833, 1.1057528117298443, 1.7446108450036957\n",
      "\u001b[36mtwitter_uncertain             \u001b[0m \u001b[32mfloat64   \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m736\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m -1.3377922604804258 | \u001b[94mMax:\u001b[0m 7.35667651474188 | \u001b[94mMean:\u001b[0m 0.016119509986544763 | \u001b[94mMedian:\u001b[0m -0.0497228122993436\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m -0.9425891343339574, 0.1965257586764516, 0.1742892656451924, -0.4683453829581953, 0.8358249333251504\n",
      "\u001b[36mtwitter_hopeful               \u001b[0m \u001b[32mfloat64   \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m509\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m -0.6067180924052868 | \u001b[94mMax:\u001b[0m 13.1791766076839 | \u001b[94mMean:\u001b[0m 0.005213470657046439 | \u001b[94mMedian:\u001b[0m -0.3648602906493361\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m 0.0199134848714944, 0.2042168899529006, -0.0073313663144526, 1.0151518723110882, 0.7718713776036319\n",
      "\u001b[36mtwitter_bearish               \u001b[0m \u001b[32mfloat64   \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m897\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m -1.0213718546321664 | \u001b[94mMax:\u001b[0m 7.388588772298218 | \u001b[94mMean:\u001b[0m 0.0511928180367343 | \u001b[94mMedian:\u001b[0m -0.0869317849732349\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m -0.2568299794566769, -0.5266682883421437, 0.0755795314891879, -1.0213718546321664, -0.6208975390640529\n",
      "\u001b[36mtwitter_pessimistic_doubtful  \u001b[0m \u001b[32mfloat64   \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m402\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m -0.4536463425833765 | \u001b[94mMax:\u001b[0m 17.84004222394468 | \u001b[94mMean:\u001b[0m -0.012319687867543228 | \u001b[94mMedian:\u001b[0m -0.4536463425833765\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m -0.4536463425833765, 0.3417314211787128, 0.6224529848594502, 0.4174816843941498, 1.0708277046272947\n",
      "\u001b[36mtwitter_sad                   \u001b[0m \u001b[32mfloat64   \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m236\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m -0.2192253059174743 | \u001b[94mMax:\u001b[0m 37.771209497566105 | \u001b[94mMean:\u001b[0m -0.003998047066839065 | \u001b[94mMedian:\u001b[0m -0.2192253059174743\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m -0.2192253059174743, 0.9679757816913876, 1.5076126396954157, 1.7802712626869246, 2.703115832812032\n",
      "\u001b[36mtwitter_fearful_concerned     \u001b[0m \u001b[32mfloat64   \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m470\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m -0.5040581722190334 | \u001b[94mMax:\u001b[0m 14.93687261104306 | \u001b[94mMean:\u001b[0m -0.02345642047405413 | \u001b[94mMedian:\u001b[0m -0.5040581722190334\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m 0.1978023179292436, 1.3125219199294482, 0.1672866444445359, -0.5040581722190334, 0.4610000017348474\n",
      "\u001b[36mtwitter_angry                 \u001b[0m \u001b[32mfloat64   \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m387\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m -0.3950215430618471 | \u001b[94mMax:\u001b[0m 22.40694113842547 | \u001b[94mMean:\u001b[0m -0.007983575898093774 | \u001b[94mMedian:\u001b[0m -0.3950215430618471\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m -0.3950215430618471, 2.2875623018190137, 0.9462703793785832, 0.690786203675644, 0.6414313060966673\n",
      "\u001b[36mtwitter_mistrustful           \u001b[0m \u001b[32mfloat64   \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m183\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m -0.1834686436859001 | \u001b[94mMax:\u001b[0m 47.97731215103217 | \u001b[94mMean:\u001b[0m 0.0009084617697872533 | \u001b[94mMedian:\u001b[0m -0.1834686436859001\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m -0.1834686436859001, 2.1099018703482937, 1.5365592418397451, 3.5212068020616445, 1.8232305560940196\n",
      "\u001b[36mtwitter_panicking             \u001b[0m \u001b[32mfloat64   \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m256\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m -0.1808721885127892 | \u001b[94mMax:\u001b[0m 55.8633697484501 | \u001b[94mMean:\u001b[0m -0.007988967523363356 | \u001b[94mMedian:\u001b[0m -0.1808721885127892\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m -0.1808721885127892, 2.154304558860664, 2.768824755537889, 4.489481306234119, 3.8222879498417033\n",
      "\u001b[36mtwitter_annoyed_frustrated    \u001b[0m \u001b[32mfloat64   \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m168\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m -0.1606813372298615 | \u001b[94mMax:\u001b[0m 60.03047190405123 | \u001b[94mMean:\u001b[0m 0.0023247178519392874 | \u001b[94mMedian:\u001b[0m -0.1606813372298615\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m -0.1606813372298615, 3.379974735786673, 2.4563253254345336, 1.914875671090176, 3.183271620619088\n",
      "\u001b[36mtwitter_bullish               \u001b[0m \u001b[32mfloat64   \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m1016\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m -1.809292424978224 | \u001b[94mMax:\u001b[0m 4.705504374978385 | \u001b[94mMean:\u001b[0m 0.0668537301583122 | \u001b[94mMedian:\u001b[0m 0.0148506790096268\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m 1.4481059750000806, -1.0428457426303874, 0.7399758880482755, 0.1451466150087588, -0.1805932249890716\n",
      "\u001b[36mtwitter_optimistic            \u001b[0m \u001b[32mfloat64   \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m831\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m -1.076684739973565 | \u001b[94mMax:\u001b[0m 6.706588517553733 | \u001b[94mMean:\u001b[0m -0.051672957640653924 | \u001b[94mMedian:\u001b[0m -0.1610055332056477\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m -0.0153292957652972, -0.6188451365896064, -0.3998783697538001, 0.2968340701783111, -0.2983574142208353\n",
      "\u001b[36mtwitter_happy                 \u001b[0m \u001b[32mfloat64   \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m546\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m -0.4687763034395767 | \u001b[94mMax:\u001b[0m 15.800927514065618 | \u001b[94mMean:\u001b[0m -0.009114717773744794 | \u001b[94mMedian:\u001b[0m -0.4687763034395767\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m -0.4687763034395767, 0.4882650975901406, 0.8870323480191894, 0.8328000019608388, 0.5172663521667987\n",
      "\u001b[36mtwitter_euphoric_excited      \u001b[0m \u001b[32mfloat64   \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m742\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m -0.9798884726054756 | \u001b[94mMax:\u001b[0m 7.939077843058166 | \u001b[94mMean:\u001b[0m -0.062181120556255444 | \u001b[94mMedian:\u001b[0m -0.1690733529996898\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m 0.2363342068032028, 0.5940467595704615, -0.5921073284461867, 1.1186918369624403, 2.5876980536599814\n",
      "\u001b[36mreddit_fomo                   \u001b[0m \u001b[32mfloat64   \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m1302\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m -0.7941303940381294 | \u001b[94mMax:\u001b[0m 25.984077787006434 | \u001b[94mMean:\u001b[0m -0.0035890322669924297 | \u001b[94mMedian:\u001b[0m -0.1565540087751635\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m 0.5969453556265235, 0.1454558579283466, -0.1410033652321642, -0.1990591011260278, -0.2791648520949645\n",
      "\u001b[36mreddit_uncertain              \u001b[0m \u001b[32mfloat64   \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m1965\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m -1.8553938968276404 | \u001b[94mMax:\u001b[0m 10.958727789064517 | \u001b[94mMean:\u001b[0m -0.03397311297481319 | \u001b[94mMedian:\u001b[0m -0.0756547737870632\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m -0.524056578812871, -0.0569206777550573, 0.0198434230590162, 0.4226721806642983, -1.3625430627548651\n",
      "\u001b[36mreddit_hopeful                \u001b[0m \u001b[32mfloat64   \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m1460\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m -1.1354792838353365 | \u001b[94mMax:\u001b[0m 18.970659098038823 | \u001b[94mMean:\u001b[0m -0.017390921925651857 | \u001b[94mMedian:\u001b[0m -0.1043952642520459\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m 0.953470158437304, -0.7827400139778949, 0.3357015733749682, 1.0985360919284597, 0.4111467455395994\n",
      "\u001b[36mreddit_bearish                \u001b[0m \u001b[32mfloat64   \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m1723\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m -0.9706798733511752 | \u001b[94mMax:\u001b[0m 15.39541213366626 | \u001b[94mMean:\u001b[0m 0.030234668096997683 | \u001b[94mMedian:\u001b[0m -0.0939249444038129\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m -0.3330399250258208, -0.109306609823942, 1.0251850055533898, -0.2432980063726227, -0.0264822575617079\n",
      "\u001b[36mreddit_pessimistic_doubtful   \u001b[0m \u001b[32mfloat64   \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m1405\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m -1.1022668545269385 | \u001b[94mMax:\u001b[0m 18.36427311493 | \u001b[94mMean:\u001b[0m 0.0026727669330022423 | \u001b[94mMedian:\u001b[0m -0.1039827535291467\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m -0.3438302323403044, 0.9468426159422128, 0.3221141188479595, -0.6696770774278954, 0.3951592969697493\n",
      "\u001b[36mreddit_sad                    \u001b[0m \u001b[32mfloat64   \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m747\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m -0.4386214180146257 | \u001b[94mMax:\u001b[0m 44.88316281613528 | \u001b[94mMean:\u001b[0m -0.007931021016814825 | \u001b[94mMedian:\u001b[0m -0.4386214180146257\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m 2.5043515842029, 0.3564976036371269, -0.4386214180146257, 0.4329513557190263, 0.6404686827984671\n",
      "\u001b[36mreddit_fearful_concerned      \u001b[0m \u001b[32mfloat64   \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m2295\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m -1.5572141469253875 | \u001b[94mMax:\u001b[0m 9.948701859793474 | \u001b[94mMean:\u001b[0m -0.019625868817109714 | \u001b[94mMedian:\u001b[0m -0.1189746460855302\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m -0.8100767438916956, 0.4613676086393244, -0.4346857560259867, 0.4882820320468541, -0.6721436848700908\n",
      "\u001b[36mreddit_angry                  \u001b[0m \u001b[32mfloat64   \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m1219\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m -0.871440684414774 | \u001b[94mMax:\u001b[0m 25.17543120662742 | \u001b[94mMean:\u001b[0m -0.001306144639569276 | \u001b[94mMedian:\u001b[0m -0.1479164652191575\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m 0.1433725061453114, -0.4144780196596478, 0.3991384322214306, -0.2926213090582807, 2.634868993225521\n",
      "\u001b[36mreddit_mistrustful            \u001b[0m \u001b[32mfloat64   \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m679\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m -0.4604635017304276 | \u001b[94mMax:\u001b[0m 24.94071506975636 | \u001b[94mMean:\u001b[0m 0.0023287542653962524 | \u001b[94mMedian:\u001b[0m -0.4604635017304276\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m 0.1993073702562421, -0.4604635017304276, 1.9024368305009007, 0.8095954268439117, 0.1103494998760169\n",
      "\u001b[36mreddit_panicking              \u001b[0m \u001b[32mfloat64   \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m607\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m -0.2360311024343057 | \u001b[94mMax:\u001b[0m 69.52619193707154 | \u001b[94mMean:\u001b[0m -0.003645004072991406 | \u001b[94mMedian:\u001b[0m -0.2360311024343057\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m 0.6699717941826534, -0.2360311024343057, 1.5080244735533406, 2.5544578191459286, 0.9463794575573188\n",
      "\u001b[36mreddit_annoyed_frustrated     \u001b[0m \u001b[32mfloat64   \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m559\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m -0.3095011321646954 | \u001b[94mMax:\u001b[0m 72.37607525872036 | \u001b[94mMean:\u001b[0m -0.006574741784531151 | \u001b[94mMedian:\u001b[0m -0.3095011321646954\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m -0.3095011321646954, 2.9209689296524184, 1.0882984138138636, 0.5071907373958109, 0.4476402885736906\n",
      "\u001b[36mreddit_bullish                \u001b[0m \u001b[32mfloat64   \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m1983\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m -1.313276196453446 | \u001b[94mMax:\u001b[0m 13.525453919216496 | \u001b[94mMean:\u001b[0m 0.04059304025858198 | \u001b[94mMedian:\u001b[0m -0.0767153534809508\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m -0.3497222928385147, -0.2719618023713447, 0.8582452838884967, -0.6537770802014485, -0.7425558073892173\n",
      "\u001b[36mreddit_optimistic             \u001b[0m \u001b[32mfloat64   \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m2112\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m -2.0225844123750503 | \u001b[94mMax:\u001b[0m 9.713747049357329 | \u001b[94mMean:\u001b[0m -0.012887273114347439 | \u001b[94mMedian:\u001b[0m -0.0665291687529873\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m 0.1112940352126549, 0.2423216591873383, -0.3050724911459219, -0.1969328516611247, 1.137197135014436\n",
      "\u001b[36mreddit_happy                  \u001b[0m \u001b[32mfloat64   \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m1400\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m -0.9160411792608166 | \u001b[94mMax:\u001b[0m 23.151623640036767 | \u001b[94mMean:\u001b[0m -0.03748462152247543 | \u001b[94mMedian:\u001b[0m -0.1560096586514192\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m 0.959361274190943, 1.1951574890986203, -0.9160411792608166, 0.1536328127079648, 0.0096382368660135\n",
      "\u001b[36mreddit_euphoric_excited       \u001b[0m \u001b[32mfloat64   \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m2421\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m -1.6859218907382054 | \u001b[94mMax:\u001b[0m 9.762386442765775 | \u001b[94mMean:\u001b[0m 0.026380131276052883 | \u001b[94mMedian:\u001b[0m -0.0865258735575022\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m -0.0504492716662083, -0.6816843176238212, -0.2897867281157688, -0.1594807796043414, -0.1448034612280543\n",
      "\u001b[36mbitcointalk_fomo              \u001b[0m \u001b[32mfloat64   \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m619\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m -0.5043594709887308 | \u001b[94mMax:\u001b[0m 21.4927203670615 | \u001b[94mMean:\u001b[0m 0.008199622868021807 | \u001b[94mMedian:\u001b[0m -0.5043594709887308\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m 1.0126805178423195, 0.2955343413040049, -0.5043594709887308, -0.1315276093268624, 0.6533815731191762\n",
      "\u001b[36mbitcointalk_uncertain         \u001b[0m \u001b[32mfloat64   \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m1293\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m -1.436343593932316 | \u001b[94mMax:\u001b[0m 8.031395758588218 | \u001b[94mMean:\u001b[0m -0.00554776547743786 | \u001b[94mMedian:\u001b[0m -0.0838094007150968\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m -1.1098698231557458, -0.4034993009300759, -0.2887388239298269, -0.0838094007150968, 0.6497684667925474\n",
      "\u001b[36mbitcointalk_hopeful           \u001b[0m \u001b[32mfloat64   \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m1046\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m -0.9783400860489664 | \u001b[94mMax:\u001b[0m 12.981920771562493 | \u001b[94mMean:\u001b[0m -0.020260087578002968 | \u001b[94mMedian:\u001b[0m -0.1058237824482503\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m 0.9472131356905448, -0.7245171613651218, 0.290774537370257, 1.514563638524508, -0.5051109044350187\n",
      "\u001b[36mbitcointalk_bearish           \u001b[0m \u001b[32mfloat64   \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m1153\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m -0.9100431925825002 | \u001b[94mMax:\u001b[0m 11.363617253904703 | \u001b[94mMean:\u001b[0m 0.04431737881187283 | \u001b[94mMedian:\u001b[0m -0.1429394146770498\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m -0.0635838514454515, -0.240570804592289, 0.2057441207345184, -0.9100431925825002, -0.2640610638200157\n",
      "\u001b[36mbitcointalk_pessimistic_doubtful\u001b[0m \u001b[32mfloat64   \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m1084\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m -0.9654354890476748 | \u001b[94mMax:\u001b[0m 12.36361475602758 | \u001b[94mMean:\u001b[0m -0.019074596863170982 | \u001b[94mMedian:\u001b[0m -0.1323698487304713\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m -0.9654354890476748, 0.0039499833214346, -0.1576142620734169, 1.4147520547157637, -0.2876871715014753\n",
      "\u001b[36mbitcointalk_sad               \u001b[0m \u001b[32mfloat64   \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m373\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m -0.2833593742235921 | \u001b[94mMax:\u001b[0m 40.47627684062989 | \u001b[94mMean:\u001b[0m -0.00721141247092284 | \u001b[94mMedian:\u001b[0m -0.2833593742235921\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m -0.2833593742235921, 1.172341919164032, 0.3249934051025792, 0.2325853879897431, 0.2601024419744543\n",
      "\u001b[36mbitcointalk_fearful_concerned \u001b[0m \u001b[32mfloat64   \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m780\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m -0.6638455384712922 | \u001b[94mMax:\u001b[0m 17.05697084253302 | \u001b[94mMean:\u001b[0m -0.0036963120695951745 | \u001b[94mMedian:\u001b[0m -0.6638455384712922\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m -0.6638455384712922, -0.3416488769984865, 0.4101433331047268, -0.0631398984372477, -0.1975082652869682\n",
      "\u001b[36mbitcointalk_angry             \u001b[0m \u001b[32mfloat64   \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m370\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m -0.340122014396572 | \u001b[94mMax:\u001b[0m 35.23545151312479 | \u001b[94mMean:\u001b[0m -0.027229642604830937 | \u001b[94mMedian:\u001b[0m -0.340122014396572\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m -0.340122014396572, 0.865829630604152, 0.1472146092681041, 0.1342189659703794, 0.1045726546974449\n",
      "\u001b[36mbitcointalk_mistrustful       \u001b[0m \u001b[32mfloat64   \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m384\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m -0.3388938089763643 | \u001b[94mMax:\u001b[0m 31.17494519116545 | \u001b[94mMean:\u001b[0m 0.004257709752261875 | \u001b[94mMedian:\u001b[0m -0.3388938089763643\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m -0.3388938089763643, 0.1952390554328189, 0.4904177436589464, 0.448952166027181, 0.0928026156831125\n",
      "\u001b[36mbitcointalk_panicking         \u001b[0m \u001b[32mfloat64   \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m452\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m -0.2650904199037042 | \u001b[94mMax:\u001b[0m 53.21244108571808 | \u001b[94mMean:\u001b[0m -0.00795387594209762 | \u001b[94mMedian:\u001b[0m -0.2650904199037042\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m -0.2650904199037042, 0.7072283347439646, 1.3554408378424103, 0.6413084191746311, 1.0718478677368406\n",
      "\u001b[36mbitcointalk_annoyed_frustrated\u001b[0m \u001b[32mfloat64   \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m236\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m -0.1539486623771155 | \u001b[94mMax:\u001b[0m 71.30018761619218 | \u001b[94mMean:\u001b[0m -0.00552969713784067 | \u001b[94mMedian:\u001b[0m -0.1539486623771155\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m -0.1539486623771155, 1.1452174517786895, 0.7505340753262931, 0.7862373412882697, 0.980243976965254\n",
      "\u001b[36mbitcointalk_bullish           \u001b[0m \u001b[32mfloat64   \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m1242\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m -1.174258117175745 | \u001b[94mMax:\u001b[0m 9.272824206073471 | \u001b[94mMean:\u001b[0m 0.055555147592679904 | \u001b[94mMedian:\u001b[0m -0.086020375170618\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m -0.453769681089592, 0.9151583474740989, 0.0920548917029481, -0.4280379512293722, -0.8201197333367884\n",
      "\u001b[36mbitcointalk_optimistic        \u001b[0m \u001b[32mfloat64   \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m1963\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m -2.253347577793104 | \u001b[94mMax:\u001b[0m 4.675090047720869 | \u001b[94mMean:\u001b[0m -0.0076830145304218065 | \u001b[94mMedian:\u001b[0m 0.0561316307115531\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m 1.091415413834331, 0.0141410996478322, -0.1538210246070518, -0.2737939705033979, 1.0347245156711542\n",
      "\u001b[36mbitcointalk_happy             \u001b[0m \u001b[32mfloat64   \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m748\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m -0.6300988874559278 | \u001b[94mMax:\u001b[0m 18.860197505496565 | \u001b[94mMean:\u001b[0m -0.02513371528127626 | \u001b[94mMedian:\u001b[0m -0.6300988874559278\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m 0.0419802985079512, 0.433008188523299, -0.0394838452452462, 0.0659831265780897, 0.0305891258644956\n",
      "\u001b[36mbitcointalk_euphoric_excited  \u001b[0m \u001b[32mfloat64   \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m1010\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m -0.8725804237619115 | \u001b[94mMax:\u001b[0m 13.993710344726528 | \u001b[94mMean:\u001b[0m -0.04663744384507469 | \u001b[94mMedian:\u001b[0m -0.1968399342851642\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m 0.6653117247024097, 0.208604359400884, 0.478900555191583, 0.1892974882729769, -0.3686383638131508\n",
      "\u001b[36mopen                          \u001b[0m \u001b[32mfloat64   \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m62625\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m 2870.9 | \u001b[94mMax:\u001b[0m 108258.38 | \u001b[94mMean:\u001b[0m 27302.92951848681 | \u001b[94mMedian:\u001b[0m 20395.8\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m 4699.0, 4689.89, 4730.05, 4740.99, 4767.0\n",
      "\u001b[36mhigh                          \u001b[0m \u001b[32mfloat64   \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m57005\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m 2950.0 | \u001b[94mMax:\u001b[0m 108353.0 | \u001b[94mMean:\u001b[0m 27429.36336732311 | \u001b[94mMedian:\u001b[0m 20490.0\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m 4724.89, 4745.35, 4766.99, 4767.0, 4734.99\n",
      "\u001b[36mlow                           \u001b[0m \u001b[32mfloat64   \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m57445\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m 2817.0 | \u001b[94mMax:\u001b[0m 107130.0 | \u001b[94mMean:\u001b[0m 27169.45282945435 | \u001b[94mMedian:\u001b[0m 20306.64\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m 4683.36, 4689.89, 4701.11, 4723.0, 4713.67\n",
      "\u001b[36mclose_binance                 \u001b[0m \u001b[32mfloat64   \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m62461\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m 2919.0 | \u001b[94mMax:\u001b[0m 108258.39 | \u001b[94mMean:\u001b[0m 27304.139813652993 | \u001b[94mMedian:\u001b[0m 20396.22\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m 4724.89, 4721.05, 4725.0, 4735.96, 4714.73\n",
      "\u001b[36mvolume                        \u001b[0m \u001b[32mfloat64   \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m64231\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m 0.0 | \u001b[94mMax:\u001b[0m 137207.1886 | \u001b[94mMean:\u001b[0m 2845.5725679610337 | \u001b[94mMedian:\u001b[0m 1570.20545\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m 12.001618, 15.711673, 28.111344, 15.140693, 16.684268\n",
      "\u001b[36mquote_asset_volume            \u001b[0m \u001b[32mfloat64   \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m64232\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m 0.0 | \u001b[94mMax:\u001b[0m 3005633669.260812 | \u001b[94mMean:\u001b[0m 71796218.92922778 | \u001b[94mMedian:\u001b[0m 34952920.4960857\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m 56396.88078226, 74145.73610788, 133018.25068186, 71825.6217862, 78802.10935386\n",
      "\u001b[36mnum_trades                    \u001b[0m \u001b[32mfloat64   \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m48378\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m 0.0 | \u001b[94mMax:\u001b[0m 1442097.0 | \u001b[94mMean:\u001b[0m 67509.84218883787 | \u001b[94mMedian:\u001b[0m 33975.0\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m 162.0, 105.0, 270.0, 147.0, 101.0\n",
      "\u001b[36mtaker_buy_base_volume         \u001b[0m \u001b[32mfloat64   \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m64226\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m 0.0 | \u001b[94mMax:\u001b[0m 68611.45039 | \u001b[94mMean:\u001b[0m 1414.7929124057598 | \u001b[94mMedian:\u001b[0m 786.03346\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m 9.227133, 2.494201, 9.947925, 9.184023, 1.914899\n",
      "\u001b[36mtaker_buy_quote_volume        \u001b[0m \u001b[32mfloat64   \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m64232\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m 0.0 | \u001b[94mMax:\u001b[0m 1502976679.7310784 | \u001b[94mMean:\u001b[0m 35559305.45358833 | \u001b[94mMedian:\u001b[0m 16929390.4189524\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m 43376.76303346, 11801.62396991, 47251.4387022, 43593.3545591, 9118.75458173\n",
      "\u001b[36mclose_augmento                \u001b[0m \u001b[32mfloat64   \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m57511\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m 3022.89 | \u001b[94mMax:\u001b[0m 108276.0 | \u001b[94mMean:\u001b[0m 27309.39019257414 | \u001b[94mMedian:\u001b[0m 20406.41\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m 4734.26, 4763.99, 4771.3, 4764.0, 4745.6\n",
      "\u001b[36mdate_datetime                 \u001b[0m \u001b[32mdatetime64[ns]\u001b[0m \u001b[33m0         \u001b[0m \u001b[35m64235\u001b[0m\n",
      "\u001b[36mdate_datetime_year            \u001b[0m \u001b[32mint32     \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m9\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m 2017 | \u001b[94mMax:\u001b[0m 2025 | \u001b[94mMean:\u001b[0m 2020.832287693625 | \u001b[94mMedian:\u001b[0m 2021.0\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m 2017, 2018, 2019, 2020, 2021\n",
      "\u001b[36mdate_datetime_month           \u001b[0m \u001b[32mint32     \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m12\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m 1 | \u001b[94mMax:\u001b[0m 12 | \u001b[94mMean:\u001b[0m 6.67078695415272 | \u001b[94mMedian:\u001b[0m 7.0\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m 8, 9, 10, 11, 12\n",
      "\u001b[36mdate_datetime_month_name      \u001b[0m \u001b[32mobject    \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m12\u001b[0m\n",
      "\u001b[36mdate_datetime_day             \u001b[0m \u001b[32mint32     \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m31\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m 1 | \u001b[94mMax:\u001b[0m 31 | \u001b[94mMean:\u001b[0m 15.688845644897642 | \u001b[94mMedian:\u001b[0m 16.0\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m 31, 1, 2, 3, 4\n",
      "\u001b[36mdate_datetime_weekday         \u001b[0m \u001b[32mint32     \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m7\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m 0 | \u001b[94mMax:\u001b[0m 6 | \u001b[94mMean:\u001b[0m 3.0035027632910407 | \u001b[94mMedian:\u001b[0m 3.0\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m 3, 4, 5, 6, 0\n",
      "\u001b[36mdate_datetime_day_name        \u001b[0m \u001b[32mobject    \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m7\u001b[0m\n",
      "\u001b[36mdate_datetime_hour            \u001b[0m \u001b[32mint32     \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m24\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m 0 | \u001b[94mMax:\u001b[0m 23 | \u001b[94mMean:\u001b[0m 11.506546275395033 | \u001b[94mMedian:\u001b[0m 12.0\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m 23, 0, 1, 2, 3\n",
      "\u001b[36mdate_datetime_minute          \u001b[0m \u001b[32mint32     \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m1\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m 0 | \u001b[94mMax:\u001b[0m 0 | \u001b[94mMean:\u001b[0m 0.0 | \u001b[94mMedian:\u001b[0m 0.0\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m 0\n",
      "\u001b[36mdate_datetime_is_weekend      \u001b[0m \u001b[32mbool      \u001b[0m \u001b[33m0         \u001b[0m \u001b[35m2\u001b[0m\n",
      "   ‚Ü≥ \u001b[94mMin:\u001b[0m False | \u001b[94mMax:\u001b[0m True | \u001b[94mMean:\u001b[0m 0.28679069043356425 | \u001b[94mMedian:\u001b[0m 0.0\n",
      "   ‚Ü≥ \u001b[96mSample unique values:\u001b[0m False, True\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Create an instance of DataWrangler\n",
    "dw = DataWrangler(\"/Users/lucpellinger/Documents/Projects/BTC-Price-Prediction/BTC_Sentiment_Reddit/baseline_data_v1.csv\")  # Replace with your CSV path\n",
    "\n",
    "dw.convert_string_dates()\n",
    "dw.extract_datetime_features()\n",
    "\n",
    "# Check the new DataFrame\n",
    "dw.summarize_basic_dataset(dw.transformed)\n",
    "\n",
    "# If needed, you can always go back to:\n",
    "# dw.df (raw loaded)\n",
    "# dw.cleaned (cleaned version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d3768570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   price_usd   price_eur price_mixed non_currency\n",
      "0  $1,000.00  1.000,00 ‚Ç¨   ‚Ç¨1.000,00        apple\n",
      "1     $100.5   1.234,56‚Ç¨  $ 1,000.00       banana\n",
      "2       2000       1000‚Ç¨   ¬£2,500.99       cherry\n",
      "3      $1.50      12,50‚Ç¨     1000.00           42\n",
      "4  $1,234.56     500,00‚Ç¨   1.000,00‚Ç¨         1234\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95müí∞ Cleaning currency fields with intelligent separator handling...\u001b[0m\n",
      "\u001b[92m‚úî Cleaned 'price_usd' (5/5 parsed, comma-dot (US))\u001b[0m\n",
      "   ‚Ü≥ \u001b[36mCurrency type column:\u001b[0m 'price_usd_currency_type'\n",
      "\u001b[92m‚úî Cleaned 'price_eur' (5/5 parsed, dot-comma (EU))\u001b[0m\n",
      "   ‚Ü≥ \u001b[36mCurrency type column:\u001b[0m 'price_eur_currency_type'\n",
      "\u001b[92m‚úî Cleaned 'price_mixed' (5/5 parsed, dot-comma (EU))\u001b[0m\n",
      "   ‚Ü≥ \u001b[36mCurrency type column:\u001b[0m 'price_mixed_currency_type'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define a dictionary with mixed-format currency data\n",
    "test_data = {\n",
    "    \"price_usd\": [\n",
    "        \"$1,000.00\",  # standard US format\n",
    "        \"$100.5\",     # US format without thousand separator\n",
    "        \"2000\",       # plain number\n",
    "        \"$1.50\",      # decimal only\n",
    "        \"$1,234.56\"   # standard US format\n",
    "    ],\n",
    "    \"price_eur\": [\n",
    "        \"1.000,00 ‚Ç¨\",  # standard EU format\n",
    "        \"1.234,56‚Ç¨\",  # EU with thousands\n",
    "        \"1000‚Ç¨\",      # no decimal\n",
    "        \"12,50‚Ç¨\",     # decimal only\n",
    "        \"500,00‚Ç¨\"     # simple EU format\n",
    "    ],\n",
    "    \"price_mixed\": [\n",
    "        \"‚Ç¨1.000,00\",   # euro with dot comma\n",
    "        \"$ 1,000.00\",   # dollar with comma dot\n",
    "        \"¬£2,500.99\",   # GBP format\n",
    "        \"1000.00\",     # plain decimal\n",
    "        \"1.000,00‚Ç¨\"    # EU style again\n",
    "    ],\n",
    "    \"non_currency\": [\n",
    "        \"apple\",       # clearly non-numeric\n",
    "        \"banana\",\n",
    "        \"cherry\",\n",
    "        \"42\",          # numeric-looking string\n",
    "        \"1234\"         # numeric-looking string\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create the DataFrame\n",
    "test_df = pd.DataFrame(test_data)\n",
    "\n",
    "# Display it\n",
    "print(test_df)\n",
    "\n",
    "cleaned_df = dw.clean_currency_fields(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8740e44f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price_usd</th>\n",
       "      <th>price_eur</th>\n",
       "      <th>price_mixed</th>\n",
       "      <th>non_currency</th>\n",
       "      <th>price_usd_currency_type</th>\n",
       "      <th>price_usd_cleaned</th>\n",
       "      <th>price_eur_currency_type</th>\n",
       "      <th>price_eur_cleaned</th>\n",
       "      <th>price_mixed_currency_type</th>\n",
       "      <th>price_mixed_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$1,000.00</td>\n",
       "      <td>1.000,00 ‚Ç¨</td>\n",
       "      <td>‚Ç¨1.000,00</td>\n",
       "      <td>apple</td>\n",
       "      <td>USD</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>EUR</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>EUR</td>\n",
       "      <td>1000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$100.5</td>\n",
       "      <td>1.234,56‚Ç¨</td>\n",
       "      <td>$ 1,000.00</td>\n",
       "      <td>banana</td>\n",
       "      <td>USD</td>\n",
       "      <td>100.50</td>\n",
       "      <td>EUR</td>\n",
       "      <td>1234.56</td>\n",
       "      <td>USD</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000</td>\n",
       "      <td>1000‚Ç¨</td>\n",
       "      <td>¬£2,500.99</td>\n",
       "      <td>cherry</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>EUR</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>GBP</td>\n",
       "      <td>2.50099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>$1.50</td>\n",
       "      <td>12,50‚Ç¨</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>42</td>\n",
       "      <td>USD</td>\n",
       "      <td>1.50</td>\n",
       "      <td>EUR</td>\n",
       "      <td>12.50</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>100000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$1,234.56</td>\n",
       "      <td>500,00‚Ç¨</td>\n",
       "      <td>1.000,00‚Ç¨</td>\n",
       "      <td>1234</td>\n",
       "      <td>USD</td>\n",
       "      <td>1234.56</td>\n",
       "      <td>EUR</td>\n",
       "      <td>500.00</td>\n",
       "      <td>EUR</td>\n",
       "      <td>1000.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   price_usd   price_eur price_mixed non_currency price_usd_currency_type  \\\n",
       "0  $1,000.00  1.000,00 ‚Ç¨   ‚Ç¨1.000,00        apple                     USD   \n",
       "1     $100.5   1.234,56‚Ç¨  $ 1,000.00       banana                     USD   \n",
       "2       2000       1000‚Ç¨   ¬£2,500.99       cherry                 UNKNOWN   \n",
       "3      $1.50      12,50‚Ç¨     1000.00           42                     USD   \n",
       "4  $1,234.56     500,00‚Ç¨   1.000,00‚Ç¨         1234                     USD   \n",
       "\n",
       "   price_usd_cleaned price_eur_currency_type  price_eur_cleaned  \\\n",
       "0            1000.00                     EUR            1000.00   \n",
       "1             100.50                     EUR            1234.56   \n",
       "2            2000.00                     EUR            1000.00   \n",
       "3               1.50                     EUR              12.50   \n",
       "4            1234.56                     EUR             500.00   \n",
       "\n",
       "  price_mixed_currency_type  price_mixed_cleaned  \n",
       "0                       EUR           1000.00000  \n",
       "1                       USD              1.00000  \n",
       "2                       GBP              2.50099  \n",
       "3                   UNKNOWN         100000.00000  \n",
       "4                       EUR           1000.00000  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a48c95",
   "metadata": {},
   "source": [
    "## Descriptive Statistics & Visual Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7910311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# UTILITY SECTION\n",
    "# =========================\n",
    "\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import re\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from factor_analyzer import FactorAnalyzer, calculate_kmo\n",
    "\n",
    "# ---- ANSI Color Codes for terminal formatting ----\n",
    "class ColorCodes:\n",
    "    \"\"\"Class for terminal color codes used in logging.\"\"\"\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKCYAN = '\\033[96m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    RED = '\\033[31m'\n",
    "    GREEN = '\\033[32m'\n",
    "    YELLOW = '\\033[33m'\n",
    "    BLUE = '\\033[34m'\n",
    "    MAGENTA = '\\033[35m'\n",
    "    CYAN = '\\033[36m'\n",
    "    WHITE = '\\033[37m'\n",
    "    BLACK = '\\033[30m'\n",
    "\n",
    "# ---- Custom formatter to strip ANSI color codes for file logging ----\n",
    "class StripColorFormatter(logging.Formatter):\n",
    "    \"\"\"Custom log formatter to remove ANSI codes from log file output.\"\"\"\n",
    "    ansi_escape = re.compile(r'(?:\\x1B[@-_][0-?]*[ -/]*[@-~])')\n",
    "\n",
    "    def format(self, record):\n",
    "        message = super().format(record)\n",
    "        return self.ansi_escape.sub('', message)\n",
    "\n",
    "# ---- Logger Initialization ----\n",
    "def reinitialize_logger(name=\"DualLogger\", log_file=\"eda_output.log\", level=logging.INFO):\n",
    "    \"\"\"\n",
    "    Initializes and configures a logger that outputs to both the terminal (with colors)\n",
    "    and a log file (without ANSI codes).\n",
    "    \"\"\"\n",
    "    logger = logging.getLogger(name)\n",
    "    logger.setLevel(level)\n",
    "\n",
    "    if logger.hasHandlers():\n",
    "        logger.handlers.clear()\n",
    "\n",
    "    console_handler = logging.StreamHandler(sys.stdout)\n",
    "    console_handler.setLevel(level)\n",
    "    console_handler.setFormatter(logging.Formatter('%(message)s'))\n",
    "\n",
    "    file_handler = logging.FileHandler(log_file, mode='w')\n",
    "    file_handler.setLevel(level)\n",
    "    file_handler.setFormatter(StripColorFormatter('%(message)s'))\n",
    "\n",
    "    logger.addHandler(console_handler)\n",
    "    logger.addHandler(file_handler)\n",
    "\n",
    "    return logger\n",
    "\n",
    "# ---- Initialize Logger ----\n",
    "log = reinitialize_logger()\n",
    "\n",
    "\n",
    "# =========================\n",
    "# DATA VISUALIZER SECTION\n",
    "# =========================\n",
    "\n",
    "class DataVisualizer:\n",
    "    \"\"\"\n",
    "    A class to perform common exploratory data analysis (EDA) visualizations on a DataFrame.\n",
    "    Supports various types of plots such as CDF, KDE, boxplots, and correlation heatmaps.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df):\n",
    "        \"\"\"Initialize the visualizer with a DataFrame.\"\"\"\n",
    "        self.df = df\n",
    "\n",
    "    def plot_cdf(self, columns: pd.DataFrame):\n",
    "        \"\"\"Plot cumulative distribution function (CDF) for selected columns.\"\"\"\n",
    "        n_cols = columns.shape[1] if len(columns.shape) > 1 else 1\n",
    "        plt.figure(figsize=(20, 5 * n_cols))\n",
    "        for i in range(n_cols):\n",
    "            plt.subplot(n_cols, 1, i + 1)\n",
    "            sorted_vals = np.sort(columns.iloc[:, i])\n",
    "            cdf = np.arange(1, len(sorted_vals) + 1) / len(sorted_vals)\n",
    "            plt.plot(sorted_vals, cdf, marker='.', linestyle='none')\n",
    "            plt.title(f'CDF Plot - {columns.columns[i]}')\n",
    "            plt.ylabel('CDF')\n",
    "            plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def plot_kernel_density(self, columns: pd.DataFrame):\n",
    "        \"\"\"Plot kernel density estimation (KDE) for selected columns.\"\"\"\n",
    "        n_cols = columns.shape[1] if len(columns.shape) > 1 else 1\n",
    "        plt.figure(figsize=(20, 5 * n_cols))\n",
    "        for i in range(n_cols):\n",
    "            plt.subplot(n_cols, 1, i + 1)\n",
    "            sns.kdeplot(columns.iloc[:, i], fill=True, color='salmon')\n",
    "            plt.title(f'Kernel Density - {columns.columns[i]}')\n",
    "            plt.ylabel('Density')\n",
    "            plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def plot_boxplot(self, columns: pd.DataFrame):\n",
    "        \"\"\"Plot boxplots for selected columns.\"\"\"\n",
    "        n_cols = columns.shape[1] if len(columns.shape) > 1 else 1\n",
    "        plt.figure(figsize=(10, 5 * n_cols))\n",
    "        for i in range(n_cols):\n",
    "            plt.subplot(n_cols, 1, i + 1)\n",
    "            sns.boxplot(y=columns.iloc[:, i], color='skyblue')\n",
    "            plt.title(f'Boxplot - {columns.columns[i]}')\n",
    "            plt.xlabel(columns.columns[i])\n",
    "            plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def plot_correlation_heatmaps(self, method: str = 'pearson'):\n",
    "        \"\"\"Plot a heatmap of the correlation matrix using the specified method ('pearson' or 'spearman').\"\"\"\n",
    "        if method not in ['pearson', 'spearman']:\n",
    "            raise ValueError(\"Method must be 'pearson' or 'spearman'.\")\n",
    "        corr = self.df.corr(method=method)\n",
    "        plt.figure(figsize=(15, 15))\n",
    "        sns.heatmap(corr, annot=False, cmap='coolwarm', vmin=-1, vmax=1, center=0)\n",
    "        plt.title(f'Correlation Heatmap ({method.title()} Coefficients)')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def log_transform_and_standardize(self):\n",
    "        \"\"\"Apply log(1+x) transformation and standardization to numeric data.\"\"\"\n",
    "        numeric_data = self.df.select_dtypes(include=[np.number])\n",
    "        log_transformed = np.log1p(numeric_data)\n",
    "        scaler = StandardScaler()\n",
    "        standardized = scaler.fit_transform(log_transformed)\n",
    "        self.transformed_df = pd.DataFrame(standardized, columns=numeric_data.columns)\n",
    "        log.info(\"‚úÖ Log transformation and standardization completed.\")\n",
    "        return self.transformed_df\n",
    "\n",
    "    def plot_elbow_method(self, max_k: int = 10):\n",
    "        \"\"\"Plot elbow curve to determine optimal number of clusters for KMeans.\"\"\"\n",
    "        data = self.transformed_df if hasattr(self, 'transformed_df') else self.df.select_dtypes(include=[np.number])\n",
    "        inertia = []\n",
    "        for k in range(1, max_k + 1):\n",
    "            kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "            kmeans.fit(data)\n",
    "            inertia.append(kmeans.inertia_)\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(range(1, max_k + 1), inertia, 'bx-')\n",
    "        plt.xlabel('k')\n",
    "        plt.ylabel('Inertia')\n",
    "        plt.title('Elbow Method For Optimal k')\n",
    "        plt.grid(True)\n",
    "        plt.savefig(\"elbow_plot.png\")\n",
    "        plt.show()\n",
    "\n",
    "    def run_kmeans_clustering(self, k: int = 4):\n",
    "        \"\"\"Run KMeans clustering and return cluster means.\"\"\"\n",
    "        data = self.transformed_df if hasattr(self, 'transformed_df') else self.df.select_dtypes(include=[np.number])\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        data['cluster_kmeans'] = kmeans.fit_predict(data)\n",
    "        grouped = data.groupby('cluster_kmeans').mean()\n",
    "        grouped.to_csv(\"kmeans_cluster_means.csv\")\n",
    "        log.info(f\"‚úÖ KMeans clustering done with {k} clusters. Results saved to CSV.\")\n",
    "        return grouped\n",
    "\n",
    "    def run_efa(self, n_factors: int = None, rotation: str = None, variance_threshold: float = 0.6):\n",
    "        \"\"\"Run exploratory factor analysis (EFA) with optional rotation and threshold-based factor selection.\"\"\"\n",
    "        data = self.transformed_df if hasattr(self, 'transformed_df') else self.df.select_dtypes(include=[np.number])\n",
    "        kmo_all, kmo_model = calculate_kmo(data)\n",
    "        log.info(f\"üîé KMO Model Score: {kmo_model:.3f}\")\n",
    "\n",
    "        # Estimate number of factors if not provided\n",
    "        fa_full = FactorAnalyzer(n_factors=data.shape[1], rotation=None)\n",
    "        fa_full.fit(data)\n",
    "        eigenvalues, _ = fa_full.get_eigenvalues()\n",
    "        var_exp = fa_full.get_factor_variance()\n",
    "        cum_var = var_exp[2]\n",
    "\n",
    "        if n_factors is None:\n",
    "            n_factors = np.argmax(cum_var >= variance_threshold) + 1\n",
    "            log.info(f\"‚úÖ Selected {n_factors} factors based on {variance_threshold*100:.1f}% variance threshold.\")\n",
    "\n",
    "        # Final factor analysis with selected number of factors\n",
    "        fa = FactorAnalyzer(n_factors=n_factors, rotation=rotation)\n",
    "        fa.fit(data)\n",
    "        loadings = fa.loadings_\n",
    "        factors = pd.DataFrame(loadings, index=data.columns, columns=[f\"Factor{i+1}\" for i in range(n_factors)])\n",
    "        factors.to_csv(\"efa_factor_loadings.csv\")\n",
    "\n",
    "        plt.figure(figsize=(20, 20))\n",
    "        sns.heatmap(factors, annot=True, cmap='coolwarm', center=0, vmin=-1, vmax=1, cbar=True)\n",
    "        plt.title(\"Factor Loadings Heatmap\")\n",
    "        plt.savefig(\"efa_heatmap.png\")\n",
    "        plt.show()\n",
    "\n",
    "        # Scree plot\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(range(1, len(eigenvalues) + 1), eigenvalues, marker='o')\n",
    "        plt.title('Scree Plot of Eigenvalues')\n",
    "        plt.xlabel('Factor Number')\n",
    "        plt.ylabel('Eigenvalue')\n",
    "        plt.axhline(y=1, color='r', linestyle='--')\n",
    "        plt.grid(True)\n",
    "        plt.savefig(\"efa_scree_plot.png\")\n",
    "        plt.show()\n",
    "\n",
    "        return factors\n",
    "\n",
    "    def parse_command(self, command):\n",
    "        \"\"\"Parse a command string with optional arguments like 'kmeans:k=3'.\"\"\"\n",
    "        if ':' in command:\n",
    "            base, args_str = command.split(':', 1)\n",
    "            args = dict(arg.split('=') for arg in args_str.split(','))\n",
    "            for k, v in args.items():\n",
    "                try:\n",
    "                    args[k] = float(v) if '.' in v else int(v)\n",
    "                except ValueError:\n",
    "                    pass\n",
    "            return base, args\n",
    "        return command, {}\n",
    "\n",
    "    def visualize(self, commands: list[str]):\n",
    "        \"\"\"Run visualizations based on list of command strings with optional arguments.\"\"\"\n",
    "        for command in commands:\n",
    "            cmd, args = self.parse_command(command)\n",
    "            if cmd == 'cdf':\n",
    "                self.plot_cdf(self.df.select_dtypes(include=[np.number]))\n",
    "            elif cmd == 'kde':\n",
    "                self.plot_kernel_density(self.df.select_dtypes(include=[np.number]))\n",
    "            elif cmd == 'boxplot':\n",
    "                self.plot_boxplot(self.df.select_dtypes(include=[np.number]))\n",
    "            elif cmd == 'pearson_corr':\n",
    "                self.plot_correlation_heatmaps(method='pearson')\n",
    "            elif cmd == 'spearman_corr':\n",
    "                self.plot_correlation_heatmaps(method='spearman')\n",
    "            elif cmd == 'log_standardize':\n",
    "                self.log_transform_and_standardize()\n",
    "            elif cmd == 'elbow':\n",
    "                self.plot_elbow_method(**args)\n",
    "            elif cmd == 'kmeans':\n",
    "                self.run_kmeans_clustering(**args)\n",
    "            elif cmd == 'efa':\n",
    "                self.run_efa(**args)\n",
    "            else:\n",
    "                log.warning(f\"Unknown visualization command: {command}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076b98e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = DataVisualizer(df)\n",
    "viz.visualize(['cdf', 'boxplot', 'pearson_corr'])\n",
    "\n",
    "viz.visualize([\n",
    "    \"log_standardize\",\n",
    "    \"elbow:max_k=8\",\n",
    "    \"kmeans:k=4\",\n",
    "    \"efa:n_factors=5,rotation=varimax\"\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b27e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_factor_analysis(df, columns, n_factors, rotation=None):\n",
    "    fa = FactorAnalyzer(n_factors=n_factors, rotation=rotation)\n",
    "    fa.fit(df[columns])\n",
    "    loadings = pd.DataFrame(fa.loadings_, index=columns)\n",
    "    return fa, loadings\n",
    "\n",
    "def plot_scree(df, columns):\n",
    "    fa = FactorAnalyzer()\n",
    "    fa.fit(df[columns])\n",
    "    ev, v = fa.get_eigenvalues()\n",
    "    plt.plot(range(1, len(ev)+1), ev, marker='o')\n",
    "    plt.title('Scree Plot')\n",
    "    plt.xlabel('Factors')\n",
    "    plt.ylabel('Eigenvalue')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c82787f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scree plot for Twitter features\n",
    "plot_scree(df_cleaned, twitter_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98237fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform FA without rotation\n",
    "fa, loadings = perform_factor_analysis(df_cleaned, twitter_cols, n_factors=3)\n",
    "sns.heatmap(loadings, annot=True, cmap=\"vlag\")\n",
    "plt.title(\"Factor Loadings (No Rotation) - Twitter\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66357a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_engineered = wrangler.engineer_relative_features(['twitter', 'reddit', 'bitcointalk'])\n",
    "df_engineered.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d3438b",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_relative = [col for col in df_engineered.columns if 'twitter_' in col and '_relative' in col]\n",
    "plot_scree(df_engineered, twitter_relative)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d965cc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "fa_rot, loadings_rot = perform_factor_analysis(df_engineered, twitter_relative, n_factors=3, rotation=\"varimax\")\n",
    "sns.heatmap(loadings_rot, annot=True, cmap=\"coolwarm\")\n",
    "plt.title(\"Factor Loadings (Varimax Rotation) - Twitter Relative\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da44e41b",
   "metadata": {},
   "source": [
    "This concludes the EDA for Twitter. Repeat similar steps for Reddit and Bitcointalk by modifying the prefix and reusing the modular `DataWrangler`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tech_club",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
